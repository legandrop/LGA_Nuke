version 13.1 v1
Gizmo {
 onCreate "import sys\nthis = nuke.thisNode()\ninference = nuke.toNode(f\"\{this.name()\}.Inference1\")\nthis[\"gpuName\"].setValue(inference[\"gpuName\"].value())\nthis[\"channelsIn\"].setValue(\"rgba.red, rgba.green, rgba.blue\")\ninference.forceValidate()\nis_enabled = inference\[\"modelFile\"\].enabled()\nif (sys.platform.lower() == \"darwin\") and (not inference\[\"useGPUIfAvailable\"\].enabled()): this\[\"useGPUIfAvailable\"\].setValue(False), this\[\"useGPUIfAvailable\"\].setEnabled(False)\nif not is_enabled:\n    for k in this.knobs(): this[k].setEnabled(False)\nthis[\"halfPrecision\"].setVisible(this[\"useGPUIfAvailable\"].enabled())"
 knobChanged "this = nuke.thisNode()\nthis[\"halfPrecision\"].setVisible(this[\"useGPUIfAvailable\"].value())"
 onDestroy "nuke.thisNode()\[\"knobChanged\"].setValue(\"\")"
 addUserKnob {20 MiDaS}
 addUserKnob {26 localGPU l "Local GPU:" T ""}
 addUserKnob {26 gpuName l "" -STARTLINE T "NVIDIA TITAN RTX"}
 addUserKnob {6 useGPUIfAvailable l "Use GPU if available" t "Select this to render on the <b>Local GPU</b>, if available.\n\nYou can select this even if no GPU is currently available on your machine. The GPU will then be used whenever the script is opened on a machine which does have a GPU available. You should also select this if you wish to render from the command line with the <b>--gpu</b> option.\n\nIf this node requires full frames from its inputs, and is therefore unable to reduce its memory overhead, it will fall back to the CPU if an attempt to render a frame on the GPU fails due to lack of memory. When this occurs, a warning message will be printed to the console." +STARTLINE}
 useGPUIfAvailable true
 addUserKnob {26 channelsIn l "Channels In:" t "The channels the model expects as input." T "rgba.red, rgba.green, rgba.blue"}
 addUserKnob {41 in_colorspace l "Input Colorspace" t "Define the colorspace that the input image is in." T OCIOColorSpace1.in_colorspace}
 addUserKnob {4 modelSize l "Model Type" t "The large model can give more detailed results but takes more time to process." M {Small Large}}
 addUserKnob {6 halfPrecision l "Optimize for Speed and Memory" t "Whether to process at half float precision. This speeds up execution and enables the processing of larger images, however there is the risk of artifacts with some trained models." +STARTLINE}
}
 Input {
  inputs 0
  name Input1
  xpos 214
  ypos -94
 }
 Reformat {
  type "to box"
  box_width {{"32*(ceil(Input1.width*(max((384/Input1.width), (384/Input1.height)))/32))"}}
  box_height {{"32*(ceil(Input1.height*(max((384/Input1.width), (384/Input1.height)))/32))"}}
  box_fixed true
  box_pixel_aspect {{Input1.pixel_aspect}}
  resize distort
  name Reformat1
  xpos 214
  ypos -35
 }
 OCIOColorSpace {
  in_colorspace scene_linear
  out_colorspace color_picking
  name OCIOColorSpace1
  xpos 214
  ypos 2
 }
set Nc367af0 [stack 0]
 Inference {
  useGPUIfAvailable {{parent.useGPUIfAvailable}}
  modelFile "\[lsearch -inline [plugins -all DPT_large.cat] *.cat]"
  halfPrecision {{parent.halfPrecision}}
  serialiseKnob {}
  name Inference2
  xpos 296
  ypos 112
  disable {{"parent.modelSize == 0"}}
 }
push $Nc367af0
 Inference {
  useGPUIfAvailable {{parent.useGPUIfAvailable}}
  modelFile "\[lsearch -inline [plugins -all MIDAS_orig.cat] *.cat]"
  halfPrecision {{parent.halfPrecision}}
  serialiseKnob {}
  name Inference1
  xpos 125
  ypos 109
  disable {{"parent.modelSize == 1"}}
 }
 Switch {
  inputs 2
  which {{parent.modelSize}}
  name Switch1
  xpos 204
  ypos 199
 }
 Reformat {
  type "to box"
  box_width {{Input1.width}}
  box_height {{Input1.height}}
  box_fixed true
  box_pixel_aspect {{Input1.pixel_aspect}}
  resize distort
  name Reformat2
  xpos 204
  ypos 225
 }
 Output {
  name Output1
  xpos 204
  ypos 257
 }
end_group
